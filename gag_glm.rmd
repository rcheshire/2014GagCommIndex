2014 Gag Commercial Handline Index of Abundance
========================================================

The 2014 update of the SEDAR 10 (2006) South Atlantic gag stock assessment requires recomputation of the commercial handline index of abundance.  The entire time series must be evaluated as recent trends will influence predictions for previous years.  This document describes changes to the methods as well as consideration of the influence of management decisions. 

**Changes from the SEDAR 10 approach**

1.  The Stephens and MacCall method for determining trips with effort in gag habitat but no catch was modified to exclude associated species with prolonged closures during part of the time series (red porgy and red snapper). The species used as factors to determine the probability of catching gag in a trip was defined as those caught in 1% of trips.  SEDAR 10 used a 5% cutoff.  


2.  The starting year for the index was changed from 1992 to 1993.  The 1992 commercial logbook data collection was voluntary.  For this reason 1992 has been excluded from all recent SEDAR assessed species.


3.  The factor for region was aggregated over the Latitude-level used in SEDAR 10 to 3 levels (North Carolina, South Carolina, and Georgia-North Florida).  This change was made to accomodate smaller samples sizes for reduced data sets discussed below.


4.  Management closures to the gag fishery occured for spawning (Jan-Apr) starting in 2010 and in October 2012 for the quota.  Three options for accounting for these changes were evaluated.  (The SEDAR 10 analysis excluded March and April due to a recreational bag limit imposed on commercial fisheries starting in 1999.) 

  *method1: 1993-2009 including all months (most similar to SEDAR 10 index)
  
  *method2:  1993-2011 excluding Jan-Apr trips (allows for longer time series and accounts for spawning closure)
  
  *method3:  1993-2012 excluding Jan-Apr trips and Oct-Dec trips  (allows for full time series and removes bias associated with spawning closure and quota closure)
  
  *method4:  1993-2012 excluding Jan-Apr trips (same as method 2 except 2012 closure in October is ignored)







```{r dataprep, warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
windows(record=T,w=7,h=5.5)
library(MASS)
require(doBy)
require(xtable)
library(matlab)
source('sort.data.frame.r')
source("DeltaGLM-1-7-2-KWS.r")
op=par()
input='W:/SEDAR/Updates2014/Gag/Indicies/CommHL'
#cpue values from SEDAR10
s10indexYr=1993:2004
s10index=c(0.944,0.907,0.937,1.001,0.768,0.951,1.017,0.912,0.867,1.006,1.342,1.44)
#1992 was dropped so, renormalize)
s10index=s10index/mean(s10index)
s10indexPred=c(0.86,1.03,1.06,0.92,0.83,0.86,0.98,1.02,0.95,1.05,1.24,1.32)
#1992 was dropped so, renormalize)
s10indexPred=s10indexPred/mean(s10indexPred)
#  read in data set created by SAS
gagtrips=read.csv(paste(input,'landbymonth.csv',sep='/'),header=TRUE)
#NMFS species codes
NMFSspp.codes=read.csv('W:/SEDAR/Updates2014/Gag/Indicies/CommHL/NMFSsppcodes.csv',header=T)
#create trip sample size for each method
method1=summaryBy(X_FREQ_~year,data=gagtrips[gagtrips$month%in%c(1,4,5,6,7,8,9,10,11,12),],FUN=sum)
colnames(method1)=c('year','method1')
for(i in 1:dim(method1)[1]){
if(method1$year[i]>2009){method1$method1[i]='NA'}
}
method2=summaryBy(X_FREQ_~year,data=gagtrips[gagtrips$month%in%5:12,],FUN=sum)
colnames(method2)=c('year','method2')
for(i in 1:dim(method2)[1]){
if(method2$year[i]>2011){method2$method2[i]='NA'}
}
method3=summaryBy(X_FREQ_~year,data=gagtrips[gagtrips$month%in%c(5,6,7,8,9),],FUN=sum)
colnames(method3)=c('year','method3')
method4=summaryBy(X_FREQ_~year,data=gagtrips[gagtrips$month%in%5:12,],FUN=sum)
colnames(method4)=c('year','method4')



```

**Table 1.** Commercial handline trips through 2009 for all months (method1), through 2011 without Jan-Apr (method2), and through 2012 with only May-Sep (method3).

```{r sample size, warning=FALSE,message=FALSE,results='asis',echo=FALSE, error=FALSE}
sstable=cbind(method1$year,method1$method1,method2$method2,method3$method3,method4$method4)
sstable=as.data.frame.matrix(sstable)
colnames(sstable)=c('year','method1','method2','method3','method4')
sstable=xtable(sstable,digits=0,display=c('d','d','d','d','d','d'),align=c('r','r','r','r','r','r'))
print(sstable,type="html",include.rownames=FALSE)
```

```{r binaryMatrixm1,warning=FALSE,message=FALSE, results='hide',echo=FALSE, error=FALSE}
###########Create Binary Matrix for Stephens and MacCall#####

####################METHOD 1. Jan,Feb, May,Jun,JUl,Aug,Sept,Oct,Nov,Dec through 2009##########
dat=read.csv('W:/SEDAR/Updates2014/Gag/Indicies/CommHL/tripspeciesm1.csv',header=T)

spp.codes=sort.data.frame(NMFSspp.codes,~sppcode)

trips=unique(dat$SCHEDULE)
spp.id=spp.codes$sppcode
spp.name=spp.codes$name

mat=matrix(0, nrow=length(trips),ncol=length(spp.id),
              dimnames=list(trip=trips,names=spp.name))
#instead of ind, this could be done using the fcn "match"
ind=1
for (j in 1:length(spp.id)) {
    if (dat$species[1]==spp.id[j]) mat[ind,j]=1
}
tic()
for (i in 2:nrow(dat)) {
    if (dat$SCHEDULE[i]!=dat$SCHEDULE[i-1]) {
        ind=ind+1
    }
    for (j in 1:length(spp.id)) {
           if (dat$species[i]==spp.id[j]) mat[ind,j]=1
    }

}
toc(echo=FALSE)
tic()
write.table(mat,file='W:/SEDAR/Updates2014/Gag/Indicies/CommHL/lgbkm1.dat',quote=F,sep=",")
toc(echo=FALSE)

#Fit logistic regression to select trips that may have caught focal species
#Implement method from Stephens and McCall.2004. Fisheries Research.
#Kyle Shertzer, 10/24/05
#Last updated, 2/13/2014
#2014 gag update - RTC

#graphics.off()
#rm(list=ls(all=TRUE))
bin.dat=mat
colnames(bin.dat)=make.names(colnames(bin.dat))
bin.dat=as.data.frame.matrix(bin.dat)
#read.csv("BinaryMatrix_HLM.csv", header=TRUE)
bin.dat[is.na(bin.dat)] <- 0
# Remove red snapper and red porgy due to closures
bin.dat=subset(bin.dat,select=-c(Red.snapper,Red.porgy))



################## regression coefficients by species###

target.spp="Gag"
target.spp2="Gag"
target.code=1423

incidence=data.frame(freq=colSums(bin.dat[,-1],na.rm=TRUE))
incidence$prop.trps=incidence$freq/sum(incidence$freq)

#----define species to be used in GLM-----                 
#minimal proportion of trips in which a species is caught
cutoff=0.01     #0.05
incidence=incidence[incidence$prop.trps>cutoff,]
mat2=bin.dat[,rownames(incidence)]
mat2=as.data.frame.matrix(mat2)
#creage scatter plot of target to other species 
#look for combinations with no overlap and remove
# windows(height=8,width=10,record=T)
# par(mfrow=c(2,4))
# for(i in 2:dim(mat2)[2]){
# with(mat2,plot(jitter(Gag),jitter(mat2[,i]),ylab=colnames(mat2[i]), xlab=target.spp))
# }


#species removed (usually because they never co-occur with target species)
#species to remove: 
#mat2=mat2[,-c(4)]
#mat2=cbind(bin.dat$SCHEDULE,mat2)
totals=colSums(mat2,na.rm=TRUE)
```
Figure 1.  Method 1:  Estimates of species-specific regression coefficients used to estimate a trip's probability of catching gag.
```{r regcoeffm1,warning=FALSE,message=FALSE,echo=FALSE,results='hide', error=FALSE}
##incidence2=data.frame(name=spp.name[incidence$prop.trps>cutoff],
##            freq=totals,prop.trps=totals/nrow(mat2))
###incidence2.sort=orderBy(~freq,incidence2)
##sp.names=spp.name[incidence$prop.trps>cutoff]
#

#-----fit binomial GLM-----
mat2.df=data.frame(mat2)
id=1:length(colnames(mat2.df))
id.target= id[colnames(mat2.df)==target.spp]
terms.glm=""
for (i in 1:length(id)) {
    if (i!=id.target){
      if (i==1) terms.glm=paste(terms.glm,colnames(mat2.df)[i],sep="")
      else terms.glm=paste(terms.glm,colnames(mat2.df)[i],sep="+")
    }
}
#fit the model and use step-wise AIC to choose species to include
model=paste(colnames(mat2.df)[id.target],terms.glm,sep="~")
glm.start <- glm(formula=as.formula(model),family="binomial", data=mat2.df)
glm.step <- stepAIC(glm.start,scope=list(upper = paste('~',terms.glm),lower = ~1),direction="backward")
fit=glm.step
#fit=glm(formula=as.formula(model),family=binomial, data=mat2.df)

coeff=sort(fit$coefficients[-1], decreasing=T)
```

```{r regcoeffPlotm1,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
windows(width=10,height=8,record=T)
par(las=2,cex.lab=1.0,oma=c(0,15,0,0))
barplot(coeff,horiz=T,xlim=c(-1.0,1), xlab='Regression coefficient')
pdf(file="sppcorr.pdf")
par=op
#savePlot(file="sppcorr.png",type="png")

```
Figure 2.  Method 1:  Absolute difference between observed and predicted number of positive gag trips.  Left and right panels differ only in the range of probabilities shown.

```{r probabilitym1,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
#-----evaluate predictions/ choose trips ------------
gt.func=function(x) length(fit$fitted.values[fit$fitted.values>x])
prob.trp=seq(0,1,by=0.001)
num.postrips.pred=rep(0,length(prob.trp))
for (i in 1:length(prob.trp)){num.postrips.pred[i]=gt.func(prob.trp[i])}

abs.dif=abs(num.postrips.pred-totals[target.spp])
windows(width=8,height=4,record=T)
par(mfcol=c(1,2),mar=c(4,4,1.5,0.5),las=2)
plot(prob.trp,abs.dif/1000,type="l",xlab="Probability",main="",ylab="Abs. error (1000)")
min.prob=mean(prob.trp[abs.dif==min(abs.dif)]) #mean in case min is not unique
plot(prob.trp[550:650],abs.dif[550:650]/1000,type="l",
     xlab="Probability", ylab="Abs. error (1000)")
pdf(file="minimum.pdf")
#savePlot(file="minimum.png",type="png")
par(mfcol=c(1,1))
par=op

```

```{r setupGLMm1,warning=FALSE,message=FALSE,results='hide',echo=FALSE, error=FALSE}
trips.pred=mat2.df[fit$fitted.values>min.prob,]
select.trips=c(rownames(trips.pred))

#-----Create data set for running delta-lognormal GLM ------------
dat.all.U=read.csv('W:/SEDAR/Updates2014/Gag/Indicies/CommHL/sa.sg.hline.U.csv',header=T)
# limit to only trips above cutoff value 
dat.select.U=dat.all.U[as.numeric(dat.all.U$SCHEDULE) %in% as.numeric(select.trips),]

dat.select.U=dat.select.U[,c('cpue','year','month','STATE')]
dat.select.U$st.fact[dat.select.U$STATE=='NC']=100
dat.select.U$st.fact[dat.select.U$STATE=='SC']=200
dat.select.U$st.fact[dat.select.U$STATE=='GN']=300
dat.select.U$stbymon=dat.select.U$st.fact+dat.select.U$month
dat.select.U=dat.select.U[,-5]
dat=dat.select.U
dat$year=as.factor(dat$year)
dat$month=as.factor(dat$month)
dat$STATE=as.factor(dat$STATE)
dat$stbymon=as.factor(dat$stbymon)


dat.pos=dat[which(dat[,"cpue"]>0),] 
#compare lognormal to gamma and determine factors to include
#Lognormal
pos.ln.start<-glm(cpue~year+month+STATE+stbymon, data=dat.pos, family=gaussian(link="identity"))
  glm.step <- stepAIC(pos.ln.start,direction="backward")
  pos.ln.fit=glm.step

#Gamma 
pos.gamma.start<-glm(cpue~year+month+STATE+stbymon, data=dat.pos, family=Gamma(link="log"))
  glm.step <- stepAIC(pos.gamma.start,direction="backward")
  pos.gamma.fit=glm.step
#binomial  
dat.bin=dat; dat.bin$cpue[dat$cpue>0]=1.0
bin.start<-glm(cpue~year+month+STATE+stbymon+stbymon, data=dat.bin, family="binomial")
  glm.step <- stepAIC(bin.start,direction="backward")
  bin.fit=glm.step
  
gagm1.ln=dglm(dat,dist="lognormal", write=T,types=c('C','F','F','F','F'))
gagm1.gamma=dglm(dat,dist="gamma", write=T,types=c('C','F','F','F','F'))
#check aic
gagm1.ln$aic
gagm1.gamma$aic


#sg.ind2=dglm(dat,dist="lognormal",write=T,types=c('C','F','F','F','F',"F"),j=F)



```


```{r binaryMatrixm2,warning=FALSE,message=FALSE, echo=FALSE, error=FALSE}
####################METHOD 2.  May,Jun,JUl,Aug,Sept,Oct,Nov,Dec through 2011##########
dat=read.csv('W:/SEDAR/Updates2014/Gag/Indicies/CommHL/tripspeciesm2.csv',header=T)
spp.codes=sort.data.frame(NMFSspp.codes,~sppcode)

trips=unique(dat$SCHEDULE)
spp.id=spp.codes$sppcode
spp.name=spp.codes$name

mat=matrix(0, nrow=length(trips),ncol=length(spp.id),
              dimnames=list(trip=trips,names=spp.name))
#instead of ind, this could be done using the fcn "match"
ind=1
for (j in 1:length(spp.id)) {
    if (dat$species[1]==spp.id[j]) mat[ind,j]=1
}
tic()
for (i in 2:nrow(dat)) {
    if (dat$SCHEDULE[i]!=dat$SCHEDULE[i-1]) {
        ind=ind+1
    }
    for (j in 1:length(spp.id)) {
           if (dat$species[i]==spp.id[j]) mat[ind,j]=1
    }

}
toc(echo=FALSE)
tic()
write.table(mat,file='W:/SEDAR/Updates2014/Gag/Indicies/CommHL/lgbkm2.dat',quote=F,sep=",")
toc(echo=FALSE)

#Fit logistic regression to select trips that may have caught focal species
#Implement method from Stephens and McCall.2004. Fisheries Research.
#Kyle Shertzer, 10/24/05
#Last updated, 2/13/2014
#2014 gag update - RTC

#graphics.off()
#rm(list=ls(all=TRUE))
bin.dat=mat
colnames(bin.dat)=make.names(colnames(bin.dat))
bin.dat=as.data.frame.matrix(bin.dat)
#read.csv("BinaryMatrix_HLM.csv", header=TRUE)
bin.dat[is.na(bin.dat)] <- 0
# Remove red snapper and red porgy due to closures
bin.dat=subset(bin.dat,select=-c(Red.snapper,Red.porgy))



################## regression coefficients by species###

target.spp="Gag"
target.spp2="Gag"
target.code=1423

incidence=data.frame(freq=colSums(bin.dat[,-1],na.rm=TRUE))
incidence$prop.trps=incidence$freq/sum(incidence$freq)

#----define species to be used in GLM-----                 
#minimal proportion of trips in which a species is caught
cutoff=0.01     #0.05
incidence=incidence[incidence$prop.trps>cutoff,]
mat2=bin.dat[,rownames(incidence)]
mat2=as.data.frame.matrix(mat2)
#creage scatter plot of target to other species 
#look for combinations with no overlap and remove
# windows(height=8,width=10,record=T)
# par(mfrow=c(2,4))
# for(i in 2:dim(mat2)[2]){
# with(mat2,plot(jitter(Gag),jitter(mat2[,i]),ylab=colnames(mat2[i]), xlab=target.spp))
# }


#species removed (usually because they never co-occur with target species)
#species to remove: 
#mat2=mat2[,-c(4)]
#mat2=cbind(bin.dat$SCHEDULE,mat2)
totals=colSums(mat2,na.rm=TRUE)
```
Figure 3.  Method 2: Estimates of species-specific regression coefficients used to estimate a trip's probability of catching gag.
```{r regcoeffm2,warning=FALSE,message=FALSE,echo=FALSE,results='hide', error=FALSE}
##incidence2=data.frame(name=spp.name[incidence$prop.trps>cutoff],
##            freq=totals,prop.trps=totals/nrow(mat2))
###incidence2.sort=orderBy(~freq,incidence2)
##sp.names=spp.name[incidence$prop.trps>cutoff]
#

#-----fit binomial GLM-----
mat2.df=data.frame(mat2)
id=1:length(colnames(mat2.df))
id.target= id[colnames(mat2.df)==target.spp]
terms.glm=""
for (i in 1:length(id)) {
    if (i!=id.target){
      if (i==1) terms.glm=paste(terms.glm,colnames(mat2.df)[i],sep="")
      else terms.glm=paste(terms.glm,colnames(mat2.df)[i],sep="+")
    }
}
#fit the model and use step-wise AIC to choose species to include
model=paste(colnames(mat2.df)[id.target],terms.glm,sep="~")
glm.start <- glm(formula=as.formula(model),family="binomial", data=mat2.df)
glm.step <- stepAIC(glm.start,scope=list(upper = paste('~',terms.glm),lower = ~1),direction="backward")
fit=glm.step
#fit=glm(formula=as.formula(model),family=binomial, data=mat2.df)

coeff=sort(fit$coefficients[-1], decreasing=T)
```

```{r regcoeffPlotm2,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
windows(width=10,height=8,record=T)
par(las=2,cex.lab=1.0,oma=c(0,15,0,0))
barplot(coeff,horiz=T,xlim=c(-1.0,1), xlab='Regression coefficient')
pdf(file="sppcorr2.pdf")
#savePlot(file="sppcorr2.png",type="png")
par=op

```
Figure 4.  Method 2: Absolute difference between observed and predicted number of positive gag trips.  Left and right panels differ only in the range of probabilities shown.

```{r probabilitym2,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
#-----evaluate predictions/ choose trips ------------
gt.func=function(x) length(fit$fitted.values[fit$fitted.values>x])
prob.trp=seq(0,1,by=0.001)
num.postrips.pred=rep(0,length(prob.trp))
for (i in 1:length(prob.trp)){num.postrips.pred[i]=gt.func(prob.trp[i])}

abs.dif=abs(num.postrips.pred-totals[target.spp])
windows(width=8,height=4,record=T)
par(mfcol=c(1,2),mar=c(4,4,1.5,0.5),las=2)
plot(prob.trp,abs.dif/1000,type="l",xlab="Probability",main="",ylab="Abs. error (1000)")
min.prob=mean(prob.trp[abs.dif==min(abs.dif)]) #mean in case min is not unique
plot(prob.trp[550:650],abs.dif[550:650]/1000,type="l",
     xlab="Probability", ylab="Abs. error (1000)")
pdf(file="minimum2.pdf")
#savePlot(file="minimum2.png",type="png")
par(mfcol=c(1,1))
par=op
```

```{r setupGLMm2,warning=FALSE,message=FALSE,results='hide',echo=FALSE, error=FALSE}
trips.pred=mat2.df[fit$fitted.values>min.prob,]
select.trips=c(rownames(trips.pred))

#-----Create data set for running delta-lognormal GLM ------------
dat.all.U=read.csv('W:/SEDAR/Updates2014/Gag/Indicies/CommHL/sa.sg.hline.U.csv',header=T)
# limit to only trips above cutoff value 
dat.select.U=dat.all.U[as.numeric(dat.all.U$SCHEDULE) %in% as.numeric(select.trips),]
#remove Jan and Feb (march and apr already  removed) due to spawning closure
dat.select.U=dat.select.U[dat.select.U$month%in%c(5,6,7,8,9,10,11,12),]
dat.select.U=dat.select.U[,c('cpue','year','month','STATE')]
dat.select.U$st.fact[dat.select.U$STATE=='NC']=100
dat.select.U$st.fact[dat.select.U$STATE=='SC']=200
dat.select.U$st.fact[dat.select.U$STATE=='GN']=300
dat.select.U$stbymon=dat.select.U$st.fact+dat.select.U$month
dat.select.U=dat.select.U[,-5]
dat=dat.select.U
dat$year=as.factor(dat$year)
dat$month=as.factor(dat$month)
dat$STATE=as.factor(dat$STATE)
dat$stbymon=as.factor(dat$stbymon)
final.dat=dat

dat.pos=dat[which(dat[,"cpue"]>0),] 
#compare lognormal to gamma and determine factors to include
#Lognormal
pos.ln.start<-glm(cpue~year+month+STATE+stbymon, data=dat.pos, family=gaussian(link="identity"))
  glm.step <- stepAIC(pos.ln.start,direction="backward")
  pos.ln.fit=glm.step

#Gamma 
pos.gamma.start<-glm(cpue~year+month+STATE+stbymon, data=dat.pos, family=Gamma(link="log"))
  glm.step <- stepAIC(pos.gamma.start,direction="backward")
  pos.gamma.fit=glm.step
#binomial  
dat.bin=dat; dat.bin$cpue[dat$cpue>0]=1.0
bin.start<-glm(cpue~year+month+STATE+stbymon, data=dat.bin, family="binomial")
  glm.step <- stepAIC(bin.start,direction="backward")
  bin.fit=glm.step
  
gagm2.ln=dglm(dat,dist="lognormal", write=T,types=c('C','F','F','F','F'))
gagm2.gamma=dglm(dat,dist="gamma", write=T,types=c('C','F','F','F','F'))
#check aic
gagm2.ln$aic
gagm2.gamma$aic
```

```{r binaryMatrixm3,warning=FALSE,message=FALSE, echo=FALSE, error=FALSE}

####################METHOD 3.  May,Jun,JUl,Aug,Septthrough 2012##########
dat=read.csv('W:/SEDAR/Updates2014/Gag/Indicies/CommHL/tripspeciesm3.csv',header=T)
spp.codes=sort.data.frame(NMFSspp.codes,~sppcode)

trips=unique(dat$SCHEDULE)
spp.id=spp.codes$sppcode
spp.name=spp.codes$name

mat=matrix(0, nrow=length(trips),ncol=length(spp.id),
              dimnames=list(trip=trips,names=spp.name))
#instead of ind, this could be done using the fcn "match"
ind=1
for (j in 1:length(spp.id)) {
    if (dat$species[1]==spp.id[j]) mat[ind,j]=1
}
tic()
for (i in 2:nrow(dat)) {
    if (dat$SCHEDULE[i]!=dat$SCHEDULE[i-1]) {
        ind=ind+1
    }
    for (j in 1:length(spp.id)) {
           if (dat$species[i]==spp.id[j]) mat[ind,j]=1
    }

}
toc(echo=FALSE)
tic()
write.table(mat,file='W:/SEDAR/Updates2014/Gag/Indicies/CommHL/lgbkm3.dat',quote=F,sep=",")
toc(echo=FALSE)

#Fit logistic regression to select trips that may have caught focal species
#Implement method from Stephens and McCall.2004. Fisheries Research.
#Kyle Shertzer, 10/24/05
#Last updated, 2/13/2014
#2014 gag update - RTC

#graphics.off()
#rm(list=ls(all=TRUE))
bin.dat=mat
colnames(bin.dat)=make.names(colnames(bin.dat))
bin.dat=as.data.frame.matrix(bin.dat)
#read.csv("BinaryMatrix_HLM.csv", header=TRUE)
bin.dat[is.na(bin.dat)] <- 0
# Remove red snapper and red porgy due to closures
bin.dat=subset(bin.dat,select=-c(Red.snapper,Red.porgy))



################## regression coefficients by species###

target.spp="Gag"
target.spp2="Gag"
target.code=1423

incidence=data.frame(freq=colSums(bin.dat[,-1],na.rm=TRUE))
incidence$prop.trps=incidence$freq/sum(incidence$freq)

#----define species to be used in GLM-----                 
#minimal proportion of trips in which a species is caught
cutoff=0.01     #0.05
incidence=incidence[incidence$prop.trps>cutoff,]
mat2=bin.dat[,rownames(incidence)]
mat2=as.data.frame.matrix(mat2)
#creage scatter plot of target to other species 
#look for combinations with no overlap and remove
# windows(height=8,width=10,record=T)
# par(mfrow=c(2,4))
# for(i in 2:dim(mat2)[2]){
# with(mat2,plot(jitter(Gag),jitter(mat2[,i]),ylab=colnames(mat2[i]), xlab=target.spp))
# }


#species removed (usually because they never co-occur with target species)
#species to remove: 
#mat2=mat2[,-c(4)]
#mat2=cbind(bin.dat$SCHEDULE,mat2)
totals=colSums(mat2,na.rm=TRUE)
```
Figure 5.  Method 3: Estimates of species-specific regression coefficients used to estimate a trip's probability of catching gag.
```{r regcoeffm3,warning=FALSE,message=FALSE,echo=FALSE,results='hide', error=FALSE}
##incidence2=data.frame(name=spp.name[incidence$prop.trps>cutoff],
##            freq=totals,prop.trps=totals/nrow(mat2))
###incidence2.sort=orderBy(~freq,incidence2)
##sp.names=spp.name[incidence$prop.trps>cutoff]
#

#-----fit binomial GLM-----
mat2.df=data.frame(mat2)
id=1:length(colnames(mat2.df))
id.target= id[colnames(mat2.df)==target.spp]
terms.glm=""
for (i in 1:length(id)) {
    if (i!=id.target){
      if (i==1) terms.glm=paste(terms.glm,colnames(mat2.df)[i],sep="")
      else terms.glm=paste(terms.glm,colnames(mat2.df)[i],sep="+")
    }
}
#fit the model and use step-wise AIC to choose species to include
model=paste(colnames(mat2.df)[id.target],terms.glm,sep="~")
glm.start <- glm(formula=as.formula(model),family="binomial", data=mat2.df)
glm.step <- stepAIC(glm.start,scope=list(upper = paste('~',terms.glm),lower = ~1),direction="backward")
fit=glm.step
#fit=glm(formula=as.formula(model),family=binomial, data=mat2.df)

coeff=sort(fit$coefficients[-1], decreasing=T)
```

```{r regcoeffPlotm3,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
windows(width=10,height=8,record=T)
par(las=2,cex.lab=1.0,oma=c(0,15,0,0))
barplot(coeff,horiz=T,xlim=c(-1.0,1), xlab='Regression coefficient')
pdf(file="sppcorr3.pdf")
#savePlot(file="sppcorr3.png",type="png")
par=op

```
Figure 6.  Method 3: Absolute difference between observed and predicted number of positive gag trips.  Left and right panels differ only in the range of probabilities shown.

```{r probabilitym3,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
#-----evaluate predictions/ choose trips ------------
gt.func=function(x) length(fit$fitted.values[fit$fitted.values>x])
prob.trp=seq(0,1,by=0.001)
num.postrips.pred=rep(0,length(prob.trp))
for (i in 1:length(prob.trp)){num.postrips.pred[i]=gt.func(prob.trp[i])}

abs.dif=abs(num.postrips.pred-totals[target.spp])
windows(width=8,height=4,record=T)
par(mfcol=c(1,2),mar=c(4,4,1.5,0.5),las=2)
plot(prob.trp,abs.dif/1000,type="l",xlab="Probability",main="",ylab="Abs. error (1000)")
min.prob=mean(prob.trp[abs.dif==min(abs.dif)]) #mean in case min is not unique
plot(prob.trp[550:650],abs.dif[550:650]/1000,type="l",
     xlab="Probability", ylab="Abs. error (1000)")
pdf(file="minimum3.pdf")
#savePlot(file="minimum3.png",type="png")
par(mfcol=c(1,1))
par=op
```

```{r setupGLMm3,warning=FALSE,message=FALSE,echo=FALSE,results='hide', error=FALSE}
trips.pred=mat2.df[fit$fitted.values>min.prob,]
select.trips=c(rownames(trips.pred))

#-----Create data set for running delta-lognormal GLM ------------
dat.all.U=read.csv('W:/SEDAR/Updates2014/Gag/Indicies/CommHL/sa.sg.hline.U.csv',header=T)
# limit to only trips above cutoff value 
dat.select.U=dat.all.U[as.numeric(dat.all.U$SCHEDULE) %in% as.numeric(select.trips),]
#remove Jan and Feb (march and apr already  removed) due to spawning closure
#remove Oct-Dec due to closure in 2012
dat.select.U=dat.select.U[dat.select.U$month%in%c(5,6,7,8,9),]
dat.select.U=dat.select.U[,c('cpue','year','month','STATE')]
dat.select.U$st.fact[dat.select.U$STATE=='NC']=100
dat.select.U$st.fact[dat.select.U$STATE=='SC']=200
dat.select.U$st.fact[dat.select.U$STATE=='GN']=300
dat.select.U$stbymon=dat.select.U$st.fact+dat.select.U$month
dat.select.U=dat.select.U[,-5]
dat=dat.select.U
dat$year=as.factor(dat$year)
dat$month=as.factor(dat$month)
dat$STATE=as.factor(dat$STATE)
dat$stbymon=as.factor(dat$stbymon)

dat.pos=dat[which(dat[,"cpue"]>0),] 
#compare lognormal to gamma and determine factors to include
#Lognormal
pos.ln.start<-glm(cpue~year+month+STATE+stbymon, data=dat.pos, family=gaussian(link="identity"))
  glm.step <- stepAIC(pos.ln.start,direction="backward")
  pos.ln.fit=glm.step

#Gamma 
pos.gamma.start<-glm(cpue~year+month+STATE+stbymon, data=dat.pos, family=Gamma(link="log"))
  glm.step <- stepAIC(pos.gamma.start,direction="backward")
  pos.gamma.fit=glm.step
#binomial  
dat.bin=dat; dat.bin$cpue[dat$cpue>0]=1.0
bin.start<-glm(cpue~year+month+STATE+stbymon, data=dat.bin, family="binomial")
  glm.step <- stepAIC(bin.start,direction="backward")
  bin.fit=glm.step
  
gagm3.ln=dglm(dat,dist="lognormal", write=T,types=c('C','F','F','F','F'))
gagm3.gamma=dglm(dat,dist="gamma", write=T,types=c('C','F','F','F','F'))
#check aic
gagm3.ln$aic
gagm3.gamma$aic
```

```{r binaryMatrixm4,warning=FALSE,message=FALSE, echo=FALSE, error=FALSE}
####################METHOD 4.  May,Jun,JUl,Aug,Sept,Oct,Nov,Dec through 2012##########
dat=read.csv('W:/SEDAR/Updates2014/Gag/Indicies/CommHL/tripspeciesm4.csv',header=T)
spp.codes=sort.data.frame(NMFSspp.codes,~sppcode)

trips=unique(dat$SCHEDULE)
spp.id=spp.codes$sppcode
spp.name=spp.codes$name

mat=matrix(0, nrow=length(trips),ncol=length(spp.id),
              dimnames=list(trip=trips,names=spp.name))
#instead of ind, this could be done using the fcn "match"
ind=1
for (j in 1:length(spp.id)) {
    if (dat$species[1]==spp.id[j]) mat[ind,j]=1
}
tic()
for (i in 2:nrow(dat)) {
    if (dat$SCHEDULE[i]!=dat$SCHEDULE[i-1]) {
        ind=ind+1
    }
    for (j in 1:length(spp.id)) {
           if (dat$species[i]==spp.id[j]) mat[ind,j]=1
    }

}
toc(echo=FALSE)
tic()
write.table(mat,file='W:/SEDAR/Updates2014/Gag/Indicies/CommHL/lgbkm4.dat',quote=F,sep=",")
toc(echo=FALSE)

#Fit logistic regression to select trips that may have caught focal species
#Implement method from Stephens and McCall.2004. Fisheries Research.
#Kyle Shertzer, 10/24/05
#Last updated, 2/13/2014
#2014 gag update - RTC

#graphics.off()
#rm(list=ls(all=TRUE))
bin.dat=mat
colnames(bin.dat)=make.names(colnames(bin.dat))
bin.dat=as.data.frame.matrix(bin.dat)
#read.csv("BinaryMatrix_HLM.csv", header=TRUE)
bin.dat[is.na(bin.dat)] <- 0
# Remove red snapper and red porgy due to closures
bin.dat=subset(bin.dat,select=-c(Red.snapper,Red.porgy))



################## regression coefficients by species###

target.spp="Gag"
target.spp2="Gag"
target.code=1423

incidence=data.frame(freq=colSums(bin.dat[,-1],na.rm=TRUE))
incidence$prop.trps=incidence$freq/sum(incidence$freq)

#----define species to be used in GLM-----                 
#minimal proportion of trips in which a species is caught
cutoff=0.01     #0.05
incidence=incidence[incidence$prop.trps>cutoff,]
mat2=bin.dat[,rownames(incidence)]
mat2=as.data.frame.matrix(mat2)
#creage scatter plot of target to other species 
#look for combinations with no overlap and remove
# windows(height=8,width=10,record=T)
# par(mfrow=c(2,4))
# for(i in 2:dim(mat2)[2]){
# with(mat2,plot(jitter(Gag),jitter(mat2[,i]),ylab=colnames(mat2[i]), xlab=target.spp))
# }


#species removed (usually because they never co-occur with target species)
#species to remove: 
#mat2=mat2[,-c(4)]
#mat2=cbind(bin.dat$SCHEDULE,mat2)
totals=colSums(mat2,na.rm=TRUE)
```
Figure 7.  Method 4: Estimates of species-specific regression coefficients used to estimate a trip's probability of catching gag.
```{r regcoeffm4,warning=FALSE,message=FALSE,echo=FALSE,results='hide', error=FALSE}
##incidence2=data.frame(name=spp.name[incidence$prop.trps>cutoff],
##            freq=totals,prop.trps=totals/nrow(mat2))
###incidence2.sort=orderBy(~freq,incidence2)
##sp.names=spp.name[incidence$prop.trps>cutoff]
#

#-----fit binomial GLM-----
mat2.df=data.frame(mat2)
id=1:length(colnames(mat2.df))
id.target= id[colnames(mat2.df)==target.spp]
terms.glm=""
for (i in 1:length(id)) {
    if (i!=id.target){
      if (i==1) terms.glm=paste(terms.glm,colnames(mat2.df)[i],sep="")
      else terms.glm=paste(terms.glm,colnames(mat2.df)[i],sep="+")
    }
}
#fit the model and use step-wise AIC to choose species to include
model=paste(colnames(mat2.df)[id.target],terms.glm,sep="~")
glm.start <- glm(formula=as.formula(model),family="binomial", data=mat2.df)
glm.step <- stepAIC(glm.start,scope=list(upper = paste('~',terms.glm),lower = ~1),direction="backward")
fit=glm.step
#fit=glm(formula=as.formula(model),family=binomial, data=mat2.df)

coeff=sort(fit$coefficients[-1], decreasing=T)
```

```{r regcoeffPlotm4,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
windows(width=10,height=8,record=T)
par(las=2,cex.lab=1.0,oma=c(0,15,0,0))
barplot(coeff,horiz=T,xlim=c(-1.0,1), xlab='Regression coefficient')
pdf(file="sppcorr4.pdf")
#savePlot(file="sppcorr4.png",type="png")
par=op

```
Figure 8.  Method 4: Absolute difference between observed and predicted number of positive gag trips.  Left and right panels differ only in the range of probabilities shown.

```{r probabilitym4,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
#-----evaluate predictions/ choose trips ------------
gt.func=function(x) length(fit$fitted.values[fit$fitted.values>x])
prob.trp=seq(0,1,by=0.001)
num.postrips.pred=rep(0,length(prob.trp))
for (i in 1:length(prob.trp)){num.postrips.pred[i]=gt.func(prob.trp[i])}

abs.dif=abs(num.postrips.pred-totals[target.spp])
windows(width=8,height=4,record=T)
par(mfcol=c(1,2),mar=c(4,4,1.5,0.5),las=2)
plot(prob.trp,abs.dif/1000,type="l",xlab="Probability",main="",ylab="Abs. error (1000)")
min.prob=mean(prob.trp[abs.dif==min(abs.dif)]) #mean in case min is not unique
plot(prob.trp[550:650],abs.dif[550:650]/1000,type="l",
     xlab="Probability", ylab="Abs. error (1000)")
pdf(file="minimum4.pdf")
#savePlot(file="minimum4.png",type="png")
par(mfcol=c(1,1))
par=op
```

```{r setupGLMm4,warning=FALSE,message=FALSE,results='hide',echo=FALSE, error=FALSE}
trips.pred=mat2.df[fit$fitted.values>min.prob,]
select.trips=c(rownames(trips.pred))

#-----Create data set for running delta-lognormal GLM ------------
dat.all.U=read.csv('W:/SEDAR/Updates2014/Gag/Indicies/CommHL/sa.sg.hline.U.csv',header=T)
# limit to only trips above cutoff value 
dat.select.U=dat.all.U[as.numeric(dat.all.U$SCHEDULE) %in% as.numeric(select.trips),]
#remove Jan and Feb (march and apr already  removed) due to spawning closure
dat.select.U=dat.select.U[dat.select.U$month%in%c(5,6,7,8,9,10,11,12),]
dat.select.U=dat.select.U[,c('cpue','year','month','STATE')]
dat.select.U$st.fact[dat.select.U$STATE=='NC']=100
dat.select.U$st.fact[dat.select.U$STATE=='SC']=200
dat.select.U$st.fact[dat.select.U$STATE=='GN']=300
dat.select.U$stbymon=dat.select.U$st.fact+dat.select.U$month
dat.select.U=dat.select.U[,-5]
dat=dat.select.U
dat$year=as.factor(dat$year)
dat$month=as.factor(dat$month)
dat$STATE=as.factor(dat$STATE)
dat$stbymon=as.factor(dat$stbymon)

dat.pos=dat[which(dat[,"cpue"]>0),] 
#compare lognormal to gamma and determine factors to include
#Lognormal
pos.ln.start<-glm(cpue~year+month+STATE+stbymon, data=dat.pos, family=gaussian(link="identity"))
  glm.step <- stepAIC(pos.ln.start,direction="backward")
  pos.ln.fit=glm.step

#Gamma 
pos.gamma.start<-glm(cpue~year+month+STATE+stbymon, data=dat.pos, family=Gamma(link="log"))
  glm.step <- stepAIC(pos.gamma.start,direction="backward")
  pos.gamma.fit=glm.step
#binomial  
dat.bin=dat; dat.bin$cpue[dat$cpue>0]=1.0
bin.start<-glm(cpue~year+month+STATE+stbymon, data=dat.bin, family="binomial")
  glm.step <- stepAIC(bin.start,direction="backward")
  bin.fit=glm.step
  
gagm4.ln=dglm(dat,dist="lognormal", write=T,types=c('C','F','F','F','F'))
gagm4.gamma=dglm(dat,dist="gamma", write=T,types=c('C','F','F','F','F'))
#check aic
gagm4.ln$aic
gagm4.gamma$aic
```
Figure 9.  Estimated index for the four methods using a lognormal error distribution.
```{r compareMethods,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
plot(rownames(gagm3.ln$deltaGLM.index),gagm3.ln$deltaGLM.index$index/mean(gagm3.ln$deltaGLM.index$index),type='n',xlab='',ylab='Pounds/hook-hr')
lines(rownames(gagm3.ln$deltaGLM.index),gagm3.ln$deltaGLM.index$index/mean(gagm3.ln$deltaGLM.index$index),lty=1,lwd=2,col='blue')
lines(rownames(gagm4.ln$deltaGLM.index),gagm4.ln$deltaGLM.index$index/mean(gagm4.ln$deltaGLM.index$index),lty=3,lwd=2,col='magenta')
lines(rownames(gagm2.ln$deltaGLM.index),gagm2.ln$deltaGLM.index$index/mean(gagm2.ln$deltaGLM.index$index),lty=1,lwd=2,col='darkorange')
lines(rownames(gagm1.ln$deltaGLM.index),gagm1.ln$deltaGLM.index$index/mean(gagm1.ln$deltaGLM.index$index),lty=1,lwd=2,col='darkgreen')
lines(s10indexYr,s10index,lty=1,lwd=2,col='red')
legend('topleft',lty=c(1,1,1,3,1),lwd=c(2,2,2,2,2), col=c('blue','darkorange','darkgreen','magenta','red'),legend=c('method 3', 'method 2', 'method 1','method 4', 'SEDAR 10'))
pdf(file="compareMethods.pdf")
#savePlot(file="compareMethods.png",type="png")

```
Method 2 allows the commercial handline index to extend to 2011 and matches the trend in the index when January and February are included.  Method 3 deviates from the trend in the index when October through December are included, especially at the end of the series.  The influence of the 2012 closure in method 4 was cause for concern.  For these reasons, method 2, May to September index through 2011 was chosen for input to the update of the SEDAR 10 gag stock assessment.  The data were fit better using a lognormal distribution as compared to a gamma distribution for all methods.  The uncertainty in the estimates were calculated from 1000 bootstrap runs of the model.

Figure 10. Diagnostics of lognormal model fits to positive CPUE data.  The histogram of empirical log CPUE, with the normal distribution (empirical mean and variance) overlaid.

```{r logposresids,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
dat.pos=final.dat[which(final.dat[,"cpue"]>0),] 
gagm2.ln=dglm(dat,dist="lognormal", write=T,types=c('C','F','F','F','F'))
ds=deltalognormal.summary 
dr=deltalognormal.results
pos.resids=dr$positive.glm$residuals
Ftest=anova(dr$positive.glm, test="F")
yrs=as.numeric(row.names(ds$deltaGLM.index))
mths=row.names(ds$effects$month)
areas=row.names(ds$effects$STATE)
stmnth=row.names(ds$effects$stbymon)

# hist(dat.pos$cpue,breaks=40,freq=FALSE,right=TRUE,xlab='CPUE (whole pounds/hook-hour)',
#      main='Gag pos commercial handline CPUE')     
# savePlot(file="poshist.png",type="png")
# pdf(file="poshist.pdf")

mu=mean(log(dat.pos$cpue)); sd=sd(log(dat.pos$cpue))
m1=min(log(dat.pos$cpue)); m2=max(log(dat.pos$cpue)); xv=seq(m1,m2,by=0.01)
d=dnorm(xv,mean=mu, sd=sd)
hist(log(dat.pos$cpue),breaks=40,freq=FALSE,right=TRUE,xlab='Log CPUE (whole pounds/hook-hour)',main='Gag pos commercial CPUE') 
            lines(xv,d, col="blue")
 # savePlot(file="histLogPos.png",type="png")
  pdf(file="histLogPos.pdf") 
```
Figure 11.  Quantile-quantile plot of residuals from the fitted model.
```{r qqplot,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
qqnorm(pos.resids,main='Gag: log residuals (pos CPUE)')
qqline(pos.resids)
#savePlot(file="qq.png",type="png")
pdf(file="qq.pdf")
```


```{r bootstrap,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}

index=gagm2.ln$deltaGLM.index[1]
years=1993:2011
nyr=length(years)
#bootstrap    custom modification to draw within year
nBoot=5 #number of bootstrap samples (residual resampling)
boot.mat=matrix(0,nrow=nBoot,ncol=nyr)
colnames(boot.mat)=years            
#n.trips=nrow(bt.inp2)
tripsbyyear=summaryBy(cpue~year,data=final.dat,FUN=length) #
yrss=tripsbyyear[,2]                                      #
#ind=1:n.trips  # define inside loop for each year
for(i in 1:nBoot){
print(paste("Starting bootstrap #", i, "out of",nBoot))
for(j in 1:length(years)){
tempyr=final.dat[final.dat$year==years[j],]
ind=1:nrow(tempyr)
row.sample=sample(x=ind,size=nrow(tempyr),replace=T)
assign(paste("gag.inp2yr",j,sep=""),tempyr[row.sample,])
}
gag.inp2.new=rbind(gag.inp2yr1,gag.inp2yr2,gag.inp2yr3,gag.inp2yr4,gag.inp2yr5,gag.inp2yr6,
  gag.inp2yr7,gag.inp2yr8,gag.inp2yr9,gag.inp2yr10,gag.inp2yr11,gag.inp2yr12,gag.inp2yr13,gag.inp2yr14,gag.inp2yr15,gag.inp2yr16,gag.inp2yr17,gag.inp2yr18,gag.inp2yr19)

gag=dglm(gag.inp2.new,dist="lognormal",write=T,types=c('C','F','F','F','F'),j=T)
boot.mat[i,]=gag$deltaGLM.index[,1]
}
```
Figure 12.  Raw residuals of lognormal model fits to positive CPUE for year.  Box-and-whisker plots give first, second (median), and third quartiles, as well as limbs that extend approximately one interquartile range beyond the nearest quartile, and outliers (circles) beyond the limbs.  Sample size is given along the upper whisker.
```{r yrresid,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
windows()
x=plot(dat.pos$year,pos.resids,main="Raw residuals (pos CPUE) - Year")
text(c(1:length(x$n)),rep(1.5,length(x$n)),x$n,srt=90)
#savePlot(file="yearresid.png",type="png")                      
pdf(file="yearresid.pdf")
```
Figure 13.  Raw residuals of lognormal model fits to positive CPUE for month.  Sample size is given along the upper whisker.
```{r monresid,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
x=plot(dat.pos$month,pos.resids,main="Raw residuals (pos CPUE) - Month")
text(c(1:length(x$n)),rep(1.5,length(x$n)),x$n,srt=90)
#savePlot(file="monthresid.png",type="png")
pdf(file="monthresid.pdf")
```

Figure 14.  Raw residuals of lognormal model fits to positive CPUE for region.  Sample size is given along the upper whisker.

```{r stateresid,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
x=plot(dat.pos$STATE,pos.resids,main="Raw residuals (pos CPUE) - State",xaxt="n")
axis(side=1,at=c(1:3),c("GA.NFL","NC","SC"))
text(c(1:length(x$n)),rep(1.5,length(x$n)),x$n,srt=90)
#savePlot(file="stateresid.png",type="png")
pdf(file="stateresid.pdf")
```

Figure 15.  Raw residuals of lognormal model fits to positive CPUE for region by month.  Sample size is given along the upper whisker.

```{r stbymonresid,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
x=plot(dat.pos$stbymon,pos.resids,main="Raw residuals (pos CPUE) - Region by Month",xaxt="n")
axis(side=1,at=c(1:24),c("NC-5","NC-6","NC-7","NC-8","NC-9","NC-10","NC-11","NC-12",
                        "SC-5","SC-6","SC-7","SC-8","SC-9","SC-10","SC-11","SC-12",
                        "Ga.NFL-5","Ga.NFL-6","Ga.NFL-7","Ga.NFL-8","Ga.NFL-9","Ga.NFL-10","Ga.NFL-11","Ga.NFL-12"))
text(c(1:length(x$n)),rep(1.5,length(x$n)),x$n,srt=90)
#savePlot(file="stbymonresid.png",type="png")
pdf(file="stbymonresid.pdf")

```

```{r plotindex,warning=FALSE,message=FALSE,echo=FALSE, error=FALSE}
#calculate annual standard deviation
index=gagm2.ln$deltaGLM.index$index
scaled.index=index/mean(index)
#cv determined with z distribution
error <- qt(0.975,df=dim(boot.mat)[1]-1)*apply(boot.mat,2,sd)/apply(boot.mat,2,mean)
cv=apply(boot.mat,2,sd)/apply(boot.mat,2,mean)
lower=scaled.index-error
upper=scaled.index+error
index.plot=cbind(years,lower,scaled.index,upper)
colnames(index.plot)=c("years","lower","index","upper")
index.plot=as.data.frame(index.plot)

nom=summaryBy(cpue~year,data=final.dat,FUN=c(mean,length))
nomcpue=nom$cpue.mean
nomcpue.std=nom$cpue.mean/mean(nom$cpue.mean)
N=nom$cpue.length
U.std=scaled.index

with(index.plot,errbar(years,index,yminus=lower,yplus=upper,ylab="CPUE (Pounds/hook-hour)",
  main="Gag - Commercial Handline",xlab="",las=2,ylim=c(-0,3)))
with(index.plot,lines(years,index,col="black",lwd=2))
with(index.plot,lines(years,nomcpue.std,lty=2,lwd=2))
legend("topleft",lty=c(1,2),lwd=c(2,2),legend=c("CPUE","Nominal CPUE"))
#savePlot(file="boot-index.png",type="png")      
pdf(file="boot-index.pdf")
#save.image(file="gag-boot-out.Rdata")

out=data.frame(years, N, nomcpue, nomcpue.std, U.std, cv)
names(out)<-c("Year", "N", "Nominal CPUE", "Relative nominal", "Standardized CPUE", "CV")
write.csv(out, file="gag.ll.lgbk.index.csv", quote=F, row.names=F)

```